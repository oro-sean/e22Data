{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This note book is built for the lisa rose etchells team\n",
    "# the purpose is to speed up the combining of logs and importing photo events to SP RRP\n",
    "# it accomplishes the following\n",
    "# 1 - clean sailmon log file and add TWD and TWS\n",
    "# 2 - calculate course and TWA **HOLD**\n",
    "# 3 - align time stamps and add measured loads and positions from cyclops and visualStringpot\n",
    "# 4 - obtain file path and time stamps from coach photos\n",
    "# 5 - cluster coach photos using time and the yachts heading and heel\n",
    "# 6 - obtain file path for onboard photos at the centre of each cluster\n",
    "# 7 - move all onboard photos to the correct project directory\n",
    "# 8 - create XML script for photo events to import photos to RRP\n",
    "# 9 - creat txt for comments for NS ASA ** HOLD **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "## The default project directory structure is based on the RRP default directory\n",
    "# the user specifies the the project folder ie 22Feb - REGATTA\n",
    "# the user also specifies the specific date of the coach photo folder ie 21\n",
    "# all coach photos are to be imported into the folder photos/coach_day\n",
    "# the vSp, cyclops and sailmon logs should be named acordingly with the date at the end"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import exifread as ex\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from tkinter import filedialog\n",
    "dir = filedialog.askdirectory()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "## Get project details from the user\n",
    "projectFolder = input(\"Please enter the RRP analysis folder\")\n",
    "day = str(input(\"Please enter the day as DD\"))\n",
    "month = str(input(\"Please enter the month as MM\"))\n",
    "year = str(input(\"Please enter the year as YY\"))\n",
    "windDir = input(\"Please enter the average wind direction\")\n",
    "windSpeed = input(\"Please enter the average wind speed\")\n",
    "## Build file names and directories\n",
    "cyclopsFile = str('lisaRose_loads_'+year+month+day+'.csv') # build the cyclops file name\n",
    "vSpFile = str('lisaRose_vSp_'+year+month+day+'.csv') # build the vSp file name\n",
    "sailmonFile = str('lisaRose_SM_'+year+month+day+'.csv') # build the sailmon file name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "directory = os.path.join(\"N:\",\"Sean O'Rourke\",\"LisaRose E22\",\n",
    "                         \"2.0 Performance Analysis\",\"2.2 KND\",\n",
    "                         \"2022\",projectFolder) # build the path to the project directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "## Import all csv files from project folder\n",
    "sailmon = pd.read_csv(os.path.join(directory,\"Logs\",sailmonFile), index_col=False) # import sailmon csv\n",
    "sailmon.rename(columns={'time': 'timeStamp'}, inplace=True) # rename columns\n",
    "sailmon['timeStamp'] = pd.to_datetime(sailmon.timeStamp, format=\"%Y-%m-%d %H:%M:%S\").dt.round('1s') # format timeStamp column to datetime object and round to 1s\n",
    "\n",
    "gate = pd.read_csv(os.path.join(directory,\"Logs\",vSpFile), index_col=0) # import mast gate vSp file\n",
    "gate['timeStamp'] = pd.to_datetime(gate['timeStamp'], format = \"%Y:%m:%d %H:%M:%S\") # make timestamp a datetime object\n",
    "gate.drop(columns = ['Dot', 'Count', 'file'], inplace = True) # drop irrelevant columns\n",
    "\n",
    "loadcells = pd.read_csv(os.path.join(directory,\"Logs\",cyclopsFile), index_col=False) # import loadcells csv\n",
    "loadcells.rename(columns={'Timestamp': 'timeStamp'}, inplace=True) # fix the column name of timeStamp\n",
    "loadcells['timeStamp'] = pd.to_datetime(loadcells.timeStamp, format=\"%Y-%m-%d %H:%M:%S\").dt.round('1s') # make the timestamp column a date time object and round to 1 second\n",
    "loadcells['Mainsheet'] = 2*loadcells.Mainsheet # double the mainsheet load as it is read off a 2:1\n",
    "loadcells['Backstay'] = 2*loadcells.Backstay# double the backstay load as it is read off a 2:1\n",
    "loadcells.drop(columns =[' Latitude', ' Longitude', ' Heading'], inplace = True) # drop unused loadcell columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "## correct timestamping on all 3 csv data frames\n",
    "sm_timeStart = sailmon.timeStamp[0] # get the first tiemstamp in the sailmon log\n",
    "lc_timeStart = loadcells.timeStamp[0] # get the first tiemstamp in the loadcell log\n",
    "ga_timeStart = gate.timeStamp[0] # get the first tiemstamp in the gate log\n",
    "\n",
    "## get the time offsets\n",
    "ts_correct = datetime.strptime(input(\"Please enter what first Sailmon time stamp should read, \"\n",
    "                                     \"the current first time stamp is \"+ str(sm_timeStart)),\n",
    "                               '%Y-%m-%d %H:%M:%S') # get the correct time for the first sailmon timestamp\n",
    "delta = ts_correct - sm_timeStart # calculate delta\n",
    "sailmon['timeStamp'] = sailmon.timeStamp + delta # apply delta to the sailmon time stamp column\n",
    "\n",
    "ts_correct = datetime.strptime(input(\"Please enter what first Loadcells time stamp should read, \"\n",
    "                                     \"the current first time stamp is \"+ str(lc_timeStart)),\n",
    "                               '%Y-%m-%d %H:%M:%S') # get the correct timestamp for the first loacells time stamp\n",
    "delta = ts_correct - lc_timeStart # calculate delta\n",
    "loadcells['timeStamp'] = loadcells.timeStamp + delta # apply the delta to the loadcells timestamp column\n",
    "\n",
    "ts_correct = datetime.strptime(input(\"Please enter what first mastGate time stamp should read, \"\n",
    "                                     \"the current first time stamp is \"+ str(ga_timeStart)),\n",
    "                               '%Y-%m-%d %H:%M:%S') # get the correct timestamp for the first mastgate time stamp\n",
    "delta = ts_correct - ga_timeStart # calculate delta\n",
    "gate['timeStamp'] = gate.timeStamp + delta # apply the delta to the mastagte timestamp column\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "## Clean and merge all csv inputs\n",
    "allData = pd.DataFrame(data = sailmon[['timeStamp', 'latitude', 'longitude', 'speed', 'HDT - Heading True', 'COG - Course over Ground', 'Heel']]) # select the relevent columns of the sailmon log to for the base data frame\n",
    "allData.rename(columns = {'HDT - Heading True': 'HDG','COG - Course over Ground': 'COG' }, inplace=True) # rename columns to remove hythons\n",
    "allData = allData.merge(gate, how = 'left', left_on='timeStamp', right_on='timeStamp') # merge all date with ther mast gate data\n",
    "allData.rename(columns = {'measure': 'mastGate'}, inplace = True) # rename the measure column to a mastgate\n",
    "allData = allData.merge(loadcells, how = 'left', left_on='timeStamp', right_on='timeStamp') # merge the loadcells dataframe\n",
    "allData.rename(columns={'timeStamp': 'time'}, inplace=True) # rename timestamo to time to better suit rrp\n",
    "allData['TWS'] = windSpeed # add true wind speed\n",
    "allData['TWD'] = windDir # add true wind direction\n",
    "# allData['TWA'] = windDir - HDG # calculate the true wind angle\n",
    "allData['speed'] = allData.speed * 1.944 # convert m/s to Knots\n",
    "allData.to_csv(os.path.join(directory,'Logs','allData_'+year+month+day+'.csv')) # export alldata as a csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Files found in folder\n",
      "20.jpg images found in folder\n",
      "The first corrected timeStamp is 2022-05-06 15:43:28\n"
     ]
    }
   ],
   "source": [
    "directory_coach = os.path.join(directory,\"Photos\",\"coach_\"+day) # define directory containing coach photos\n",
    "def get_photo_path(directory, filter, criteria):\n",
    "    file_list = [f for f in listdir(directory) if isfile(join(directory, f))] # inspect directory and return list of files\n",
    "    print(str(len(file_list))+' Files found in folder')\n",
    "    if filter: # if filter is set as true\n",
    "        file_list = [file for file in file_list if criteria in file] # remove any files not containing .jpg\n",
    "        print(str(len(file_list))+str(criteria)+' images found in folder')\n",
    "\n",
    "    timeStamps = [] # create an empty list to append timeStamps to\n",
    "    for file in file_list: # iterate over all files in the file list\n",
    "        filepath = os.path.join(directory,file) # create the path to each individual photo\n",
    "        photo = open(filepath, 'rb') # open photo\n",
    "        tags = ex.process_file(photo) # get the photos exif tags\n",
    "        ts = datetime.strptime(str(tags['EXIF DateTimeOriginal']), '%Y:%m:%d %H:%M:%S') # extract photos time stamp\n",
    "        timeStamps.append(ts) # append timestamp to list\n",
    "\n",
    "    return file_list, timeStamps\n",
    "\n",
    "file_list, timeStamps = get_photo_path(directory_coach, True, \".jpg\")\n",
    "## correct timestamps\n",
    "\n",
    "def correct_timestamp(timeStamps, varName):\n",
    "    ts_correct = datetime.strptime(input(\"Please enter what first \"+str(varName)+\" time stamp should read, \"\n",
    "                                     \"the current first time stamp is \"+ str(min(timeStamps))),\n",
    "                               '%Y-%m-%d %H:%M:%S') # get the correct timestamp for the first mastgate time stamp\n",
    "    delta = ts_correct - min(timeStamps) # calculate delta\n",
    "    timeStamps = [ts + delta for ts in timeStamps] # iterate over timestamps and add delta\n",
    "    print(\"The first corrected timeStamp is \"+str(min(timeStamps)))\n",
    "    return timeStamps\n",
    "\n",
    "timeStamps = correct_timestamp(timeStamps, 'Coach Photos')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "features = pd.DataFrame({'time': timeStamps}) # make features dataframe\n",
    "features = pd.merge(features, allData[['time','HDG','Heel','speed']], on = 'time') # merge relevent parts of allData to features\n",
    "timeStep = features.time - features.time[0] # subtract the first time stamp from all other stamps to give time from the first photo\n",
    "## make timeStep a numeric type\n",
    "timeStep = [time.total_seconds() for time in timeStep] # convert timestep to seconds\n",
    "features[\"timeStep\"] = timeStep # add timeStep to features\n",
    "features = features[['timeStep']] # select final features for clustering\n",
    "features = features.to_numpy() # convert features to a numpy array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "## scale features and cluster\n",
    "scaler = preprocessing.StandardScaler().fit(features) # define scikitlearn scaler\n",
    "features_scaled = scaler.transform(features) # apply scaller and create new scaled array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "noClusters = input(\"Enter the number of clusters\")\n",
    "kmeans = KMeans(n_clusters = noClusters) # define cluster object\n",
    "cluster = kmeans.fit(features_scaled) # find clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "labels = kmeans.labels_ # create list of labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "# label each coach photo with cluster label, then group by cluster label, then find median time of group, then find jib and main picture at this time, then adjust time stamps so no confilcts then create photo events\n",
    "cluster_df = pd.DataFrame({'cluster': labels, 'file': file_list, 'timeStamp': timeStamps}) # create a df with the cluster label, file name and time stamp\n",
    "photos_df = pd.DataFrame({'directory': directory_coach,'file': file_list, 'timeStamp': timeStamps})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "times_to_fetch = cluster_df[['cluster', 'timeStamp']].groupby(['cluster']).mean() # create a list of the average time of each cluster\n",
    "## need to work out order of clusters --> do I??"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "times_to_fetch = times_to_fetch.timeStamp.round('S')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "## define jib and main photo directorys\n",
    "directory_jib = os.path.join(directory,\"Photos\",\"jib_\"+day) # define directory containing jib photos\n",
    "directory_main = os.path.join(directory,\"Photos\",\"main_\"+day) # define directory containing main photos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Files found in folder\n",
      "6 Files found in folder\n"
     ]
    }
   ],
   "source": [
    "for dir in [directory_jib, directory_main]:\n",
    "    file_list, timeStamps = get_photo_path(dir,False,'crit')\n",
    "    availablePhotos = pd.DataFrame({'timeStamp': timeStamps, 'file': file_list})\n",
    "    availablePhotos = availablePhotos.set_index('timeStamp').sort_index()\n",
    "    file_list = [file_list[i] for i in list(np.unique(availablePhotos.index.get_indexer(times_to_fetch, method='nearest')))]\n",
    "    timeStamps = [timeStamps[i] for i in list(np.unique(availablePhotos.index.get_indexer(times_to_fetch, method='nearest')))]\n",
    "    newPhotos = pd.DataFrame({'directory': dir,'file': file_list, 'timeStamp': timeStamps})\n",
    "    photos_df = pd.concat([photos_df,newPhotos])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "## change time stamps so as no 2 are the same\n",
    "\n",
    "timeStamps = list(photos_df.timeStamp)\n",
    "\n",
    "\n",
    "while len(np.unique(timeStamps)) < len(timeStamps): # continue to iterate over time and add time to times until all timestamps are unique\n",
    "    duplicates = []\n",
    "    for time in timeStamps:\n",
    "        count = 0\n",
    "        for i in range(len(timeStamps)):\n",
    "            if time == timeStamps[i]:\n",
    "                count += 1\n",
    "            if count > 1:\n",
    "                duplicates.append(i)\n",
    "\n",
    "    for n in duplicates:\n",
    "        timeStamps[n] = timeStamps[n] + timedelta(seconds=1)\n",
    "\n",
    "photos_df['timeStamps'] = timeStamps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}